%=========================================
% 	  Vorgehensweise      		 =
%=========================================
\chapter{Vorgehensweise}
In diesem Kapitel wird zuerst die Aufgabenstellung erkl"art, um zu erfahren was eigentlich gemacht werden soll. Danach wird noch der Weg beschrieben wie man genau vorgegangen ist, um diese Aufgabe zu l"osen.

\section{Aufgabenstellung}
Gelernte Wortrepr"asentationen (word embeddings) stellen W"orter basierend auf ihren Kontexten als Vektoren dar. Diese Vektoren erfassen die Bedeutung der W"orter, so dass W"orter mit "ahnlicher Bedeutung auf zueinander naheliegende Vektoren abgebildet werden. Zudem erlauben diese Vektoren einfache Arithmetik, subtrahiert man vom Vektor des Wortes \textit{king} den Vektor des Wortes \textit{man} und addiert jenen des Wortes \textit{woman}, erh"alt man einen Vektor in der N"ahe des Vektors des Wortes \textit{queen}.\\
Die Aufgabe ist, inwiefern sich solche Wortrepr"asentationen eignen, um auf langzeitlichen Dokumentensammlungen, die Ver"anderung unserer Sprache sowie die Ver"anderung von Bedeutungen zu analysieren.

\section{L"osung}
Die Daten die f"ur die Analyse ben"otigt werden, kommen aus der New York Times, beginnend mit dem Jahr 1987 und endet mit dem Jahr 2007.
Zur Vorbereitung der Analyse m"ussen erst alle ben"otigten Daten nach ihrer Jahreszahl aufgeteilt werden, zuz"uglich m"ussen Gro"s- und Kleinschreibung sowie die Satzzeichen entfernt werden. Diese vorverarbeiteten Daten werden in entsprechende Textdokumente gespeichert. Nachdem eine gewisse Zeit vergangen ist, werden die Wortrepr"asentationen f"ur jedes der in der Dokumentensammlung enthaltenen Jahre berechnet und sind in einer Datenbank indexiert und gespeichert worden. Dies bildet die Grundlage der Analyse.
Zur Speicherung der Daten wurde MySQL verwendet, auch wenn PostgreSQL als \acs{RDBMS} m"oglich gewesen w"are, habe ich mich f"ur MySQL entschieden, da ich fr"uher schon mal mit MySQL gearbeitet habe.
Nachdem alles in der Datenbank gespeichert ist, wird mit Hilfe von SQL-Kommandos die Daten, nach der Euklidischen Distanz und der Kosinus-"Ahnlichkeit, ausgelesen, um zu ermitteln welche W"orter zu einem gesuchten Wort zu finden sind, welche sich in der Sprache sowie in der Bedeutung ver"andert haben.
%Hier wird erkl√§rt was genau gemacht wurde